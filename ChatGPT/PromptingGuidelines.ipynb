{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT Prompting Guidelines"
      ],
      "metadata": {
        "id": "rvDggJM3iWa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###There are broadly two types of LLMs\n",
        "\n",
        "####Base LLM : Predicts next word, based on text training data often trained on large amount of data found on the internet\n",
        "\n",
        "####Instruction Tuned LLM : Tries to follow instructions as it is Fine-tuned on instructions and good attempts at following those instructions and then Reinforcement Learning with Human Feedback(RHLF)"
      ],
      "metadata": {
        "id": "Maa-zCAsivkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Guidelines for Prompting"
      ],
      "metadata": {
        "id": "-yE8fbdgkPSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two Key Principles for writing prompts:\n",
        "\n",
        "1. Write clear and specific instructions\n",
        "2. Give the model time to think"
      ],
      "metadata": {
        "id": "6Bd1YSIOowWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyNYm2rCiBYq",
        "outputId": "9f761f5d-4d1f-405f-857e-1bbebcca9e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.21.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "xaEphEHarc8S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai')"
      ],
      "metadata": {
        "id": "FNOZlbKrrVh5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "46q3Jc4PpywH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
        "  messages = [{'role':'user','content':prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0,\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "KT0YzsJvrpat"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Principle 1 : Write clear and specific instructions|"
      ],
      "metadata": {
        "id": "JLiz0dqb9aCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tactics\n",
        "\n",
        "\n",
        "###Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "- Delimiters can be anything like: ```, ---,\"\"\", < >, `<tag> </tag>`, `:`"
      ],
      "metadata": {
        "id": "pObk_-fYsctI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "You should express what you want a model to do by\n",
        "providing instructions that are as clear and\n",
        "specific as you can possibly make them.\n",
        "This will guide the model towards the desired output,\n",
        "and reduce the chances of receiving irrelevant\n",
        "or incorrect responses. Don't confuse writing a\n",
        "clear prompt with writing a short prompt.\n",
        "In many cases, longer prompts provide more clarity\n",
        "and context for the model, which can lead to\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks\n",
        "into a single sentence.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC804nNCsDl8",
        "outputId": "ac5b7df4-bbb7-4bdb-ebf7-11c52fc125e1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is important to provide clear and specific instructions to guide a model towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, even if it means writing longer prompts for more clarity and context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Delimiters helps to avoid prompt injections(conflicting instructions to the model)"
      ],
      "metadata": {
        "id": "ovVDAsBF70XS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tactic 2: Ask for structured output"
      ],
      "metadata": {
        "id": "Pqua3Qj5tGo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HTML, JSON"
      ],
      "metadata": {
        "id": "6P1ODz0N8IM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along\n",
        "with their authors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfKeRG7s0dx",
        "outputId": "435ce93f-4e90-4a7c-fa43-0448c7c05095"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"book_id\": 1,\n",
            "        \"title\": \"The Midnight Garden\",\n",
            "        \"author\": \"Elena Rivers\",\n",
            "        \"genre\": \"Fantasy\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 2,\n",
            "        \"title\": \"Echoes of the Past\",\n",
            "        \"author\": \"Nathan Black\",\n",
            "        \"genre\": \"Mystery\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 3,\n",
            "        \"title\": \"Whispers in the Wind\",\n",
            "        \"author\": \"Samantha Reed\",\n",
            "        \"genre\": \"Romance\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tactic 3 : Ask the model to check whether conditions are satisfied"
      ],
      "metadata": {
        "id": "-AKRJ22N8Yy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check assumptions required to do the task"
      ],
      "metadata": {
        "id": "wtV_ERNu9llf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some\n",
        "water boiling. While that's happening,\n",
        "grab a cup and put a tea bag in it. Once the water is\n",
        "hot enough, just pour it over the tea bag.\n",
        "Let it sit for a bit so the tea can steep. After a\n",
        "few minutes, take out the tea bag. If you\n",
        "like, you can add some sugar or milk to taste.\n",
        "And that's it! You've got yourself a delicious\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions,\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions,\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHQPeKJV8NVG",
        "outputId": "e6450c26-3aed-4d0e-99eb-73b88d2ac09f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Take out the tea bag.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are\n",
        "singing. It's a beautiful day to go for a\n",
        "walk in the park. The flowers are blooming, and the\n",
        "trees are swaying gently in the breeze. People\n",
        "are out and about, enjoying the lovely weather.\n",
        "Some are having picnics, while others are playing\n",
        "games or simply relaxing on the grass. It's a\n",
        "perfect day to spend time outdoors and appreciate the\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions,\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions,\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fACWHeDW8yKI",
        "outputId": "c918716c-ed7c-431c-9261-2b6dbb125d71"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tactic 4 : \"Few-shot\" prompting"
      ],
      "metadata": {
        "id": "opS99lxZ86yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give successful examples of completing the tasks and then ask the model to perform the task"
      ],
      "metadata": {
        "id": "YOpIXMoJ9Dpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest\n",
        "valley flows from a modest spring; the\n",
        "grandest symphony originates from a single note;\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om2hTQ1E85YP",
        "outputId": "cc783cf1-ebce-4a5a-e0b8-dd7bb4b7f332"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: Resilience is like a tree that bends in the storm but does not break. It is the ability to bounce back from adversity, to persevere in the face of challenges, and to find strength in difficult times. Just as a tree grows stronger with each storm it weathers, so too can we grow stronger through resilience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second principle is to give the model time to think.\n",
        "If a model is making reasoning errors by\n",
        "rushing to an incorrect conclusion, you should try reframing the query\n",
        "to request a chain or series of relevant reasoning\n",
        "before the model provides its final answer. Another way to think about\n",
        "this is that if you give a model a task that's\n",
        "too complex for it to do in a short amount\n",
        "of time or in a small number of words, it\n",
        "may make up a guess which is likely to be incorrect. And\n",
        "you know, this would happen for a person too. If\n",
        "you ask someone to complete a complex math\n",
        "question without time to work out the answer first, they\n",
        "would also likely make a mistake. So, in these situations, you\n",
        "can instruct the model to think longer about a problem, which\n",
        "means it's spending more computational effort on\n",
        "the task."
      ],
      "metadata": {
        "id": "bIMUmjGn_QFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Principle 2 : Give the model time to think\n"
      ],
      "metadata": {
        "id": "Wobdrtc_9fyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tactic 1 : Specify the steps required to complete the task"
      ],
      "metadata": {
        "id": "rX9ku9o49_5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on\n",
        "a quest to fetch water from a hilltop\n",
        "well. As they climbed, singing joyfully, misfortune\n",
        "struck—Jack tripped on a stone and tumbled\n",
        "down the hill, with Jill following suit.\n",
        "Though slightly battered, the pair returned home to\n",
        "comforting embraces. Despite the mishap,\n",
        "their adventurous spirits remained undimmed, and they\n",
        "continued exploring with delight.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following\n",
        "keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he5ugB7b9RLL",
        "outputId": "3fdf7e46-419d-4e81-bce8-099457d1c5cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "1 - Jack and Jill go on a quest to fetch water, but encounter misfortune along the way, yet remain adventurous.\n",
            "\n",
            "2 - Jack et Jill partent en quête d'eau, mais rencontrent des malheurs en chemin, tout en restant aventureux.\n",
            "\n",
            "3 - Jack, Jill\n",
            "\n",
            "4 - \n",
            "{\n",
            "  \"french_summary\": \"Jack et Jill partent en quête d'eau, mais rencontrent des malheurs en chemin, tout en restant aventureux.\",\n",
            "  \"num_names\": 2\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask a specified format"
      ],
      "metadata": {
        "id": "Ix5HrIdM-ZB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = get_completion(prompt_2)\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScNa7LEB-VwO",
        "outputId": "69d818e9-1177-448f-fd1c-2d0a2f5630db"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "Summary: Jack and Jill, two siblings, go on a quest to fetch water from a hilltop well but encounter misfortune along the way.\n",
            "\n",
            "Translation: Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits au sommet d'une colline mais rencontrent des malheurs en chemin.\n",
            "\n",
            "Names: Jack, Jill\n",
            "\n",
            "Output JSON: \n",
            "{\n",
            "  \"french_summary\": \"Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits au sommet d'une colline mais rencontrent des malheurs en chemin.\",\n",
            "  \"num_names\": 2\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next tactic is to instruct the model to work out its own\n",
        "solution before rushing to a conclusion. And again, sometimes\n",
        "we get better results when we kind of explicitly\n",
        "instruct the models to reason out its own solution\n",
        "before coming to a conclusion. And this is kind of\n",
        "the same idea that we were discussing about\n",
        "giving the model time to actually work things\n",
        "out before just kind of saying if an\n",
        "answer is correct or not, in the same way that a person would."
      ],
      "metadata": {
        "id": "9gcI70Ma_nc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ],
      "metadata": {
        "id": "zbAqzrDx-mxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost\n",
        "me a flat $100k per year, and an additional $10 / square\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErGqjgnG-e7h",
        "outputId": "4aaef2e2-1cd3-4e88-bd37-d6a65610c632"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet is indeed 450x + 100,000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The student solution above is wrong because it just skimmed and arrived at the same conclusion. We can fix this by instructing the model to work out its own solution first"
      ],
      "metadata": {
        "id": "B_9b8Zzd_7I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost\n",
        "me a flat $100k per year, and an additional $10 / square\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neqLzYk6-_Qf",
        "outputId": "e6fead74-9c30-4acf-e9aa-0beef7b64e93"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for the first year of operations, we need to add up the costs of land, solar panels, and maintenance.\n",
            "\n",
            "Given:\n",
            "- Land cost: $100 / square foot\n",
            "- Solar panel cost: $250 / square foot\n",
            "- Maintenance cost: $100,000 flat + $10 / square foot\n",
            "\n",
            "Let x be the size of the installation in square feet.\n",
            "\n",
            "Costs:\n",
            "1. Land cost: $100x\n",
            "2. Solar panel cost: $250x\n",
            "3. Maintenance cost: $100,000 + $10x\n",
            "\n",
            "Total cost: $100x + $250x + $100,000 + $10x = $360x + $100,000\n",
            "\n",
            "Therefore, the total cost for the first year of operations as a function of the number of square feet is $360x + $100,000.\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "```\n",
            "No\n",
            "```\n",
            "Student grade:\n",
            "```\n",
            "Incorrect\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an example of how asking the model to do a calculation itself and breaking\n",
        "down the task into steps to give the\n",
        "model more time to think can help you\n",
        "get more accurate responses."
      ],
      "metadata": {
        "id": "7OsLz_RsAgov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Limitations: Hallucinations"
      ],
      "metadata": {
        "id": "67gW6lXBAmAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's really important to keep these in\n",
        "mind while you're kind of developing applications with large language models.\n",
        "So, even though the language model has been exposed to\n",
        "a vast amount of knowledge during its training process,\n",
        "it has not perfectly memorized the information\n",
        "it's seen, and so, it doesn't know the boundary of\n",
        "its knowledge very well. This means that it might\n",
        "try to answer questions about obscure topics and can\n",
        "make things up that sound plausible but are not actually true. And\n",
        "we call these fabricated ideas hallucinations."
      ],
      "metadata": {
        "id": "-as63RcMAtnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQOfUr-5AJtK",
        "outputId": "69bef782-02a3-4932-852b-a3db87fbe943"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush designed to provide a superior cleaning experience. It features ultra-soft bristles that are gentle on the gums and teeth, while still effectively removing plaque and debris. The toothbrush also has a slim design that makes it easy to maneuver and reach all areas of the mouth.\n",
            "\n",
            "One of the standout features of the AeroGlide UltraSlim Smart Toothbrush is its smart technology. It connects to a mobile app that tracks your brushing habits and provides personalized recommendations for improving your oral hygiene routine. The app also includes a timer to ensure you are brushing for the recommended two minutes.\n",
            "\n",
            "The toothbrush is made from durable, antimicrobial materials that resist bacteria growth and can be easily cleaned and sanitized. It is also eco-friendly, as the brush head is replaceable and the handle is made from recyclable materials.\n",
            "\n",
            "Overall, the AeroGlide UltraSlim Smart Toothbrush by Boie is a sleek and innovative toothbrush that offers a superior cleaning experience and helps you maintain optimal oral health.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Boie is a real company, the product name is not real.\n",
        "\n",
        "This is an example of\n",
        "where the model confabulates a description of a\n",
        "made-up product name from a real toothbrush company."
      ],
      "metadata": {
        "id": "KRlkZ0EDA7G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tactic to reduce hallucinations, in the\n",
        "case that you want the model to kind of\n",
        "generate answers based on a text, is to ask\n",
        "the model to first find any relevant quotes from the text and\n",
        "then ask it to use those quotes to kind of answer questions.\n",
        "And kind of having a way to trace the answer back\n",
        "to the source document is often pretty helpful\n",
        "to kind of reduce these hallucinations."
      ],
      "metadata": {
        "id": "V76Lych-BrZ9"
      }
    }
  ]
}