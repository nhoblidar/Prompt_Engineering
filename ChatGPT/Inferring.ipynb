{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Inferring"
      ],
      "metadata": {
        "id": "rvDggJM3iWa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tasks where the model takes a text as input and\n",
        "performs some kind of analysis. So this could be extracting labels,\n",
        "extracting names, kind of understanding the\n",
        "sentiment of a text, that kind of thing.\n",
        "So if you want to extract a sentiment, positive or negative,\n",
        "of a piece of text, in the traditional\n",
        "machine learning workflow, you'd have to collect the label data set, train\n",
        "a model, figure out how to deploy the model somewhere in\n",
        "the cloud and make inferences. And that could work pretty well, but\n",
        "it was, you know, just a lot of work to\n",
        "go through that process. And also for every task, such\n",
        "as sentiment versus extracting names versus\n",
        "something else, you have to train and\n",
        "deploy a separate model. One of the really nice\n",
        "things about large language model is that for\n",
        "many tasks like these, you can just write a\n",
        "prompt and have it start generating results pretty\n",
        "much right away. And that gives tremendous speed in terms\n",
        "of application development. And you can also just use one model, one\n",
        "API to do many different tasks rather than\n",
        "needing to figure out how to train and deploy a lot of\n",
        "different models."
      ],
      "metadata": {
        "id": "fnz7fmsUMnQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyNYm2rCiBYq",
        "outputId": "9f761f5d-4d1f-405f-857e-1bbebcca9e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.21.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "xaEphEHarc8S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai')"
      ],
      "metadata": {
        "id": "FNOZlbKrrVh5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "46q3Jc4PpywH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model = 'gpt-3.5-turbo'):\n",
        "  messages = [{'role':'user', 'content':prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature = 0\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "KT0YzsJvrpat"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product review text"
      ],
      "metadata": {
        "id": "JLiz0dqb9aCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OC804nNCsDl8"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment (positive/negative)"
      ],
      "metadata": {
        "id": "RtmNTGesKVwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUPLEGItFOj9",
        "outputId": "0b6a7d59-90d4-4118-e41a-d10cee7eb16b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the review is positive. The reviewer is satisfied with the lamp, the customer service, and the company in general.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\"\n",
        "or \"negative\".\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfKeRG7s0dx",
        "outputId": "2c312aa5-022e-4bc7-eff1-dec16a8c751e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify types of emotions"
      ],
      "metadata": {
        "id": "-AKRJ22N8Yy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the\n",
        "following review is expressing. Include no more than\n",
        "five items in the list. Format your answer as a list of\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHQPeKJV8NVG",
        "outputId": "783c7bf0-8bc8-4ea1-d5de-20d0778b3a3a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy, satisfied, grateful, impressed, content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract product and company name from customer reviews"
      ],
      "metadata": {
        "id": "opS99lxZ86yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks.\n",
        "Format your response as a JSON object with\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\"\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om2hTQ1E85YP",
        "outputId": "41616f60-f596-4497-fa87-002cd3873e5d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do multiple tasks at once"
      ],
      "metadata": {
        "id": "PVqrxBWXK-Vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are trying to\n",
        "summarize many reviews from an online shopping e-commerce website,\n",
        "it might be useful for your large collection of reviews\n",
        "to figure out what were the items, who made\n",
        "the item, figure out positive and negative\n",
        "sentiment, to track trends about positive or negative sentiment\n",
        "for specific items or for specific\n",
        "manufacturers. And in this example, we can ask it to format your response as a JSON object with \"Item\" and \"Brand\" as\n",
        "the keys. And so if we do that, it says the\n",
        "item is a lamp, the brand is Lumina, and you can easily load this\n",
        "into the Python dictionary to then do additional processing\n",
        "on this output."
      ],
      "metadata": {
        "id": "yGr07k8BN37u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks.\n",
        "Format your response as a JSON object with\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\"\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pym78u1wK_W5",
        "outputId": "1010b0be-03f2-437a-e888-63acad40516a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Sentiment\": \"positive\",\n",
            "    \"Anger\": false,\n",
            "    \"Item\": \"lamp\",\n",
            "    \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inferring topics"
      ],
      "metadata": {
        "id": "oxcZkiEQNpQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government,\n",
        "public sector employees were asked to rate their level\n",
        "of satisfaction with the department they work at.\n",
        "The results revealed that NASA was the most popular\n",
        "department with a satisfaction rating of 95%.\n",
        "\n",
        "One NASA employee, John Smith, commented on the findings,\n",
        "stating, \"I'm not surprised that NASA came out on top.\n",
        "It's a great place to work with amazing people and\n",
        "incredible opportunities. I'm proud to be a part of\n",
        "such an innovative organization.\"\n",
        "\n",
        "The results were also welcomed by NASA's management team,\n",
        "with Director Tom Johnson stating, \"We are thrilled to\n",
        "hear that our employees are satisfied with their work at NASA.\n",
        "We have a talented and dedicated team who work tirelessly\n",
        "to achieve our goals, and it's fantastic to see that their\n",
        "hard work is paying off.\"\n",
        "\n",
        "The survey also revealed that the\n",
        "Social Security Administration had the lowest satisfaction\n",
        "rating, with only 45% of employees indicating they were\n",
        "satisfied with their job. The government has pledged to\n",
        "address the concerns raised by employees in the survey and\n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ajgL26EpL10Q"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Infer 5 topics"
      ],
      "metadata": {
        "id": "U0uxlO-GNwMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long.\n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnorsvEXNt9Q",
        "outputId": "da18c71d-21d2-4634-8927-fbb672515318"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Survey\n",
            "2. Job satisfaction\n",
            "3. NASA\n",
            "4. Social Security Administration\n",
            "5. Government pledge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_list = [\n",
        "    \"nasa\", \"local government\", \"engineering\",\n",
        "    \"employee satisfaction\", \"federal government\"\n",
        "]"
      ],
      "metadata": {
        "id": "atJ1NFLKPS66"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a news alert for certain topics"
      ],
      "metadata": {
        "id": "gXW0-P_TPcSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as follows:\n",
        "item from the list: 0 or 1\n",
        "\n",
        "List of topics: {\", \".join(topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBcsgTFXPb7m",
        "outputId": "d3ae4aac-b50c-4122-8e60-97d977de9480"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nasa: 1\n",
            "local government: 0\n",
            "engineering: 0\n",
            "employee satisfaction: 1\n",
            "federal government: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In machine learning, this is sometimes called a \"Zero-Shot Learning Algorithm\",\n",
        "because we didn't give it any training data that was\n",
        "labeled, so that's Zero-Shot. And with just a prompt, it\n",
        "was able to determine which of these topics are covered in that news article."
      ],
      "metadata": {
        "id": "ioyNedFgQEso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
        "if topic_dict['nasa'] == 1:\n",
        "    print(\"ALERT: New NASA story!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQVh5mUvP43u",
        "outputId": "ede032d3-f7c7-41fa-c1ab-388b0cdb45f6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT: New NASA story!\n"
          ]
        }
      ]
    }
  ]
}